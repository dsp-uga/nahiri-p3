{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "exempt-chain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from keras_unet.models import custom_unet\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras_unet.metrics import iou, iou_thresholded\n",
    "import tensorflow as tf \n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU') \n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "IMG_LOC = '/home/clint/projects/DSP/data/p3/project3/data/'\n",
    "MASK_LOC = '/home/clint/projects/DSP/data/p3/project3/masks/'\n",
    "TRAIN_TXT = '/home/clint/projects/DSP/data/p3/project3/train.txt'\n",
    "TEST_TXT = '/home/clint/projects/DSP/data/p3/project3/test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "virgin-columbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_preprocessing(img_loc, mask_loc):\n",
    "    pairs = []\n",
    "    with open(TRAIN_TXT) as train_file:\n",
    "        for line in train_file:\n",
    "            line = line.replace('\\n', '')\n",
    "            for im_file in os.listdir(f'{img_loc}/{line}/data/{line}'):\n",
    "                pairs.append([f'{img_loc}/{line}/data/{line}/{im_file}',f'{mask_loc}/{line}.png'])\n",
    "\n",
    "        return pairs\n",
    "pairs = img_preprocessing(IMG_LOC, MASK_LOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ordinary-executive",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs = pairs[:4000]\n",
    "val_pairs = pairs[:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "surrounded-fence",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical ,Sequence\n",
    "class DataGenerator(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    \n",
    "    def __init__(self, pair, batch_size=16, dim=(224,224,3), shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.pair = pair\n",
    "#         self.class_map = class_map\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.pair) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [k for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.pair))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        batch_imgs = list()\n",
    "        batch_labels = list()\n",
    "\n",
    "        # Generate data\n",
    "        for i in list_IDs_temp:\n",
    "            # Store sample\n",
    "            img = Image.open(self.pair[i][0])\n",
    "            mask = Image.open(self.pair[i][1])\n",
    "            width, height = img.size   # Get dimensions\n",
    "            left = (width - 256)/2\n",
    "            top = (height - 256)/2\n",
    "            right = (width + 256)/2\n",
    "            bottom = (height + 256)/2\n",
    "            # Crop the center of the image\n",
    "            img = img.crop((left, top, right, bottom))\n",
    "            mask = mask.crop((left, top, right, bottom))\n",
    "            img = np.asarray(img, dtype=np.float32)/255\n",
    "            batch_imgs.append(img)\n",
    "            \n",
    "            mask = np.asarray(mask, dtype=np.float32)/2\n",
    "            batch_labels.append(mask)\n",
    "\n",
    "            \n",
    "        return np.array(batch_imgs) ,np.array(batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "unavailable-gender",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_size = 256\n",
    "train_generator = DataGenerator(train_pairs,batch_size=4, dim=(img_size,img_size,1) ,shuffle=True)\n",
    "train_steps = train_generator.__len__()\n",
    "train_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "demanding-district",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 256, 256)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,y = train_generator.__getitem__(1)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "compliant-facing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_generator = DataGenerator(val_pairs,batch_size=4, dim=(img_size,img_size,1) ,shuffle=True)\n",
    "val_steps = val_generator.__len__()\n",
    "val_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "czech-bundle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(tensor, nfilters, size=3, padding='same', initializer=\"he_normal\"):\n",
    "    x = Conv2D(filters=nfilters, kernel_size=(size, size), padding=padding, kernel_initializer=initializer)(tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(filters=nfilters, kernel_size=(size, size), padding=padding, kernel_initializer=initializer)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def deconv_block(tensor, residual, nfilters, size=3, padding='same', strides=(2, 2)):\n",
    "    y = Conv2DTranspose(nfilters, kernel_size=(size, size), strides=strides, padding=padding)(tensor)\n",
    "    y = concatenate([y, residual], axis=3)\n",
    "    y = conv_block(y, nfilters)\n",
    "    return y\n",
    "\n",
    "\n",
    "def Unet(h, w, filters):\n",
    "# down\n",
    "    input_layer = Input(shape=(h, w, 1), name='image_input')\n",
    "    conv1 = conv_block(input_layer, nfilters=filters)\n",
    "    conv1_out = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = conv_block(conv1_out, nfilters=filters*2)\n",
    "    conv2_out = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = conv_block(conv2_out, nfilters=filters*4)\n",
    "    conv3_out = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = conv_block(conv3_out, nfilters=filters*8)\n",
    "    conv4_out = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    conv4_out = Dropout(0.5)(conv4_out)\n",
    "    conv5 = conv_block(conv4_out, nfilters=filters*16)\n",
    "    conv5 = Dropout(0.5)(conv5)\n",
    "# up\n",
    "    deconv6 = deconv_block(conv5, residual=conv4, nfilters=filters*8)\n",
    "    deconv6 = Dropout(0.5)(deconv6)\n",
    "    deconv7 = deconv_block(deconv6, residual=conv3, nfilters=filters*4)\n",
    "    deconv7 = Dropout(0.5)(deconv7) \n",
    "    deconv8 = deconv_block(deconv7, residual=conv2, nfilters=filters*2)\n",
    "    deconv9 = deconv_block(deconv8, residual=conv1, nfilters=filters)\n",
    "    output_layer = Conv2D(filters=1, kernel_size=(1, 1), activation='softmax')(deconv9)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer, name='Unet')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "immediate-california",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical ,Sequence\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, concatenate, Conv2DTranspose, BatchNormalization, Activation, Dropout\n",
    "from tensorflow.keras.optimizers import Adadelta, Nadam ,Adam\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "binary-orientation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Unet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "image_input (InputLayer)        [(None, 256, 256, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 256, 256, 1)  10          image_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 256, 256, 1)  4           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 256, 256, 1)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 256, 256, 1)  10          activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 256, 256, 1)  4           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 256, 256, 1)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 128, 128, 1)  0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 128, 128, 2)  20          max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 128, 128, 2)  8           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 128, 128, 2)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 128, 128, 2)  38          activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 128, 128, 2)  8           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 128, 128, 2)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 64, 64, 2)    0           activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 64, 64, 4)    76          max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 64, 64, 4)    16          conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 64, 64, 4)    0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 64, 64, 4)    148         activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 64, 64, 4)    16          conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 64, 64, 4)    0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 32, 32, 4)    0           activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 32, 32, 8)    296         max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 32, 32, 8)    32          conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 32, 32, 8)    0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 32, 32, 8)    584         activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 32, 32, 8)    32          conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 32, 32, 8)    0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 16, 16, 8)    0           activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 16, 16, 8)    0           max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 16)   1168        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 16, 16, 16)   64          conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 16, 16, 16)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 16)   2320        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 16, 16, 16)   64          conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 16, 16)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 16, 16, 16)   0           activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 32, 32, 8)    1160        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 16)   0           conv2d_transpose_4[0][0]         \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 32, 32, 8)    1160        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 32, 32, 8)    32          conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 32, 32, 8)    0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 32, 32, 8)    584         activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 32, 32, 8)    32          conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 32, 32, 8)    0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32, 32, 8)    0           activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 64, 64, 4)    292         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 64, 64, 8)    0           conv2d_transpose_5[0][0]         \n",
      "                                                                 activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 64, 64, 4)    292         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 64, 64, 4)    16          conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 64, 64, 4)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 64, 64, 4)    148         activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 64, 64, 4)    16          conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 64, 64, 4)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 64, 64, 4)    0           activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTrans (None, 128, 128, 2)  74          dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 128, 128, 4)  0           conv2d_transpose_6[0][0]         \n",
      "                                                                 activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 128, 128, 2)  74          concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 128, 128, 2)  8           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 128, 128, 2)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 128, 128, 2)  38          activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 128, 128, 2)  8           conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 128, 128, 2)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTrans (None, 256, 256, 1)  19          activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 256, 256, 2)  0           conv2d_transpose_7[0][0]         \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 256, 256, 1)  19          concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 256, 256, 1)  4           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 256, 256, 1)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 256, 256, 1)  10          activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 256, 256, 1)  4           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 256, 256, 1)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 256, 256, 1)  2           activation_35[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 8,910\n",
      "Trainable params: 8,726\n",
      "Non-trainable params: 184\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Unet(img_size , img_size , 1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "monetary-recruitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy' ,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "neither-study",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = ModelCheckpoint(mode='max', filepath='top-weights.h5', monitor='val_acc',save_best_only='True', save_weights_only='True', verbose=1)\n",
    "es = EarlyStopping(mode='max', monitor='val_acc', patience=10, verbose=0)\n",
    "tb = TensorBoard(log_dir=\"logs/\", histogram_freq=0, write_graph=True, write_images=False)\n",
    "rl = ReduceLROnPlateau(monitor='val_acc',factor=0.1,patience=5,verbose=1,mode=\"max\",min_lr=0.0001)\n",
    "cv = CSVLogger(\"logs/log.csv\" , append=True , separator=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-portland",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clint/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1000/1000 [==============================] - 200s 198ms/step - loss: 495.5219 - accuracy: 0.1071 - val_loss: 496.6812 - val_accuracy: 0.1076\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 197s 197ms/step - loss: 495.7636 - accuracy: 0.1083 - val_loss: 496.6813 - val_accuracy: 0.1076\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 3/30\n",
      " 876/1000 [=========================>....] - ETA: 20s - loss: 493.1253 - accuracy: 0.1072"
     ]
    }
   ],
   "source": [
    "results = model.fit_generator(train_generator, \n",
    "                              steps_per_epoch=train_steps,\n",
    "                              epochs=30,\n",
    "                              validation_data=val_generator,\n",
    "                              validation_steps=val_steps,\n",
    "                              callbacks=[mc,es,tb,rl,cv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-cedar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-conservation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-mirror",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "failing-balloon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-layer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "english-auction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-binary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-steel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-reynolds",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-vietnam",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-bankruptcy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-explorer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apparent-geometry",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
